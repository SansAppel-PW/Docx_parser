#!/usr/bin/env python3
"""
è¯¦ç»†å¯¹æ¯”ä¸¤ä¸ªç‰ˆæœ¬çš„document.jsonå†…å®¹
"""

import os
import sys
import json
import time
import subprocess
import logging
from difflib import SequenceMatcher

logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

def run_single_test(script_name, test_file, output_dir):
    """è¿è¡Œå•ä¸ªæ–‡ä»¶è§£ææµ‹è¯•"""
    logger.info(f"ğŸš€ è¿è¡Œ {script_name}...")
    
    # åˆ›å»ºä¸´æ—¶è„šæœ¬æ¥ä¿®æ”¹è¾“å‡ºç›®å½•
    temp_script = f"temp_{script_name}"
    
    try:
        # è¯»å–åŸè„šæœ¬
        with open(script_name, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # ä¿®æ”¹è¾“å‡ºç›®å½•
        if script_name == "docx_parser.py":
            modified_content = content.replace(
                'output_dir = f"parsed_docs/single_files/{safe_name}"',
                f'output_dir = "{output_dir}"'
            )
        else:  # docx_parser_modular.py
            modified_content = content.replace(
                'output_dir = f"parsed_docs/single_files/{safe_name}"',
                f'output_dir = "{output_dir}"'
            )
        
        # å†™å…¥ä¸´æ—¶è„šæœ¬
        with open(temp_script, 'w', encoding='utf-8') as f:
            f.write(modified_content)
        
        # è¿è¡Œè§£æ
        start_time = time.time()
        result = subprocess.run([
            sys.executable, temp_script, test_file
        ], capture_output=True, text=True, timeout=60)
        
        end_time = time.time()
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if os.path.exists(temp_script):
            os.remove(temp_script)
        
        if result.returncode == 0:
            logger.info(f"âœ… {script_name} è¿è¡ŒæˆåŠŸï¼Œè€—æ—¶ {end_time - start_time:.2f}s")
            return True
        else:
            logger.error(f"âŒ {script_name} è¿è¡Œå¤±è´¥:")
            logger.error(f"STDERR: {result.stderr}")
            return False
            
    except Exception as e:
        logger.error(f"âŒ è¿è¡Œ {script_name} å¼‚å¸¸: {e}")
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if os.path.exists(temp_script):
            os.remove(temp_script)
        return False

def deep_compare_json(obj1, obj2, path=""):
    """æ·±åº¦å¯¹æ¯”ä¸¤ä¸ªJSONå¯¹è±¡çš„å·®å¼‚"""
    differences = []
    
    if type(obj1) != type(obj2):
        differences.append({
            "path": path,
            "type": "type_mismatch",
            "original": str(type(obj1).__name__),
            "modular": str(type(obj2).__name__)
        })
        return differences
    
    if isinstance(obj1, dict):
        # æ£€æŸ¥ç¼ºå¤±çš„é”®
        for key in obj1:
            if key not in obj2:
                differences.append({
                    "path": f"{path}.{key}" if path else key,
                    "type": "missing_key_in_modular",
                    "original": f"å­˜åœ¨ ({type(obj1[key]).__name__})",
                    "modular": "ç¼ºå¤±"
                })
            else:
                differences.extend(deep_compare_json(obj1[key], obj2[key], f"{path}.{key}" if path else key))
        
        # æ£€æŸ¥æ–°å¢çš„é”®
        for key in obj2:
            if key not in obj1:
                differences.append({
                    "path": f"{path}.{key}" if path else key,
                    "type": "extra_key_in_modular",
                    "original": "ç¼ºå¤±",
                    "modular": f"å­˜åœ¨ ({type(obj2[key]).__name__})"
                })
    
    elif isinstance(obj1, list):
        if len(obj1) != len(obj2):
            differences.append({
                "path": f"{path}[length]",
                "type": "length_mismatch",
                "original": len(obj1),
                "modular": len(obj2)
            })
        
        min_len = min(len(obj1), len(obj2))
        for i in range(min_len):
            differences.extend(deep_compare_json(obj1[i], obj2[i], f"{path}[{i}]"))
    
    else:  # åŸºæœ¬ç±»å‹
        if obj1 != obj2:
            # å¯¹äºå­—ç¬¦ä¸²ï¼Œè®¡ç®—ç›¸ä¼¼åº¦
            if isinstance(obj1, str) and isinstance(obj2, str):
                similarity = SequenceMatcher(None, obj1, obj2).ratio()
                differences.append({
                    "path": path,
                    "type": "value_mismatch",
                    "original": obj1[:100] + "..." if len(str(obj1)) > 100 else str(obj1),
                    "modular": obj2[:100] + "..." if len(str(obj2)) > 100 else str(obj2),
                    "similarity": f"{similarity:.2%}"
                })
            else:
                differences.append({
                    "path": path,
                    "type": "value_mismatch",
                    "original": obj1,
                    "modular": obj2
                })
    
    return differences

def analyze_json_content(original_path, modular_path):
    """åˆ†æä¸¤ä¸ªJSONæ–‡ä»¶çš„å†…å®¹å·®å¼‚"""
    logger.info("ğŸ“„ åˆ†æJSONå†…å®¹å·®å¼‚...")
    
    # è¯»å–JSONæ–‡ä»¶
    try:
        with open(original_path, 'r', encoding='utf-8') as f:
            original_data = json.load(f)
    except Exception as e:
        logger.error(f"è¯»å–åŸå§‹ç‰ˆæœ¬JSONå¤±è´¥: {e}")
        return None
    
    try:
        with open(modular_path, 'r', encoding='utf-8') as f:
            modular_data = json.load(f)
    except Exception as e:
        logger.error(f"è¯»å–æ¨¡å—åŒ–ç‰ˆæœ¬JSONå¤±è´¥: {e}")
        return None
    
    # æ·±åº¦å¯¹æ¯”
    differences = deep_compare_json(original_data, modular_data)
    
    # åˆ†æå…³é”®æŒ‡æ ‡
    analysis = {
        "metadata_comparison": compare_metadata(
            original_data.get("metadata", {}),
            modular_data.get("metadata", {})
        ),
        "sections_comparison": compare_sections(
            original_data.get("sections", []),
            modular_data.get("sections", [])
        ),
        "images_comparison": compare_images(
            original_data.get("images", {}),
            modular_data.get("images", {})
        ),
        "processing_info_comparison": compare_processing_info(
            original_data.get("processing_info", {}),
            modular_data.get("processing_info", {})
        ),
        "detailed_differences": differences[:50]  # é™åˆ¶æ˜¾ç¤ºå‰50ä¸ªå·®å¼‚
    }
    
    return analysis

def compare_metadata(original_meta, modular_meta):
    """å¯¹æ¯”å…ƒæ•°æ®"""
    comparison = {}
    
    key_fields = ["title", "author", "created", "modified", "file_size"]
    for field in key_fields:
        original_val = original_meta.get(field, "N/A")
        modular_val = modular_meta.get(field, "N/A")
        comparison[field] = {
            "original": original_val,
            "modular": modular_val,
            "match": original_val == modular_val
        }
    
    return comparison

def compare_sections(original_sections, modular_sections):
    """å¯¹æ¯”ç« èŠ‚ç»“æ„"""
    return {
        "count": {
            "original": len(original_sections),
            "modular": len(modular_sections),
            "match": len(original_sections) == len(modular_sections)
        },
        "structure_analysis": analyze_section_structure(original_sections, modular_sections)
    }

def analyze_section_structure(original_sections, modular_sections):
    """åˆ†æç« èŠ‚ç»“æ„"""
    def count_content_types(sections):
        counts = {"paragraphs": 0, "tables": 0, "images": 0, "smartart": 0, "embedded_objects": 0}
        
        def traverse_section(section):
            content = section.get("content", [])
            for item in content:
                item_type = item.get("type", "unknown")
                if item_type == "paragraph":
                    counts["paragraphs"] += 1
                elif item_type == "table":
                    counts["tables"] += 1
                elif item_type == "image":
                    counts["images"] += 1
                elif item_type == "smartart":
                    counts["smartart"] += 1
                elif item_type == "embedded_object":
                    counts["embedded_objects"] += 1
                elif item_type == "section":
                    traverse_section(item)
        
        for section in sections:
            traverse_section(section)
        return counts
    
    original_counts = count_content_types(original_sections)
    modular_counts = count_content_types(modular_sections)
    
    return {
        "original": original_counts,
        "modular": modular_counts,
        "differences": {
            key: modular_counts[key] - original_counts[key]
            for key in original_counts
        }
    }

def compare_images(original_images, modular_images):
    """å¯¹æ¯”å›¾ç‰‡ä¿¡æ¯"""
    return {
        "count": {
            "original": len(original_images),
            "modular": len(modular_images),
            "difference": len(modular_images) - len(original_images)
        }
    }

def compare_processing_info(original_info, modular_info):
    """å¯¹æ¯”å¤„ç†ä¿¡æ¯"""
    key_metrics = ["blocks_processed", "tables_found", "images_found"]
    comparison = {}
    
    for metric in key_metrics:
        original_val = original_info.get(metric, 0)
        modular_val = modular_info.get(metric, 0)
        comparison[metric] = {
            "original": original_val,
            "modular": modular_val,
            "difference": modular_val - original_val
        }
    
    return comparison

def print_detailed_comparison(analysis):
    """æ‰“å°è¯¦ç»†çš„å¯¹æ¯”ç»“æœ"""
    print("\n" + "="*100)
    print("ğŸ“Š DOCX Parser JSONå†…å®¹è¯¦ç»†å¯¹æ¯”æŠ¥å‘Š")
    print("="*100)
    
    # å…ƒæ•°æ®å¯¹æ¯”
    print("\nğŸ“‹ å…ƒæ•°æ®å¯¹æ¯”:")
    metadata = analysis["metadata_comparison"]
    for field, data in metadata.items():
        match_icon = "âœ…" if data["match"] else "âŒ"
        print(f"   {match_icon} {field}: {data['original']} â†’ {data['modular']}")
    
    # ç« èŠ‚ç»“æ„å¯¹æ¯”
    print("\nğŸ“š ç« èŠ‚ç»“æ„å¯¹æ¯”:")
    sections = analysis["sections_comparison"]
    count_match = "âœ…" if sections["count"]["match"] else "âŒ"
    print(f"   {count_match} ç« èŠ‚æ•°é‡: {sections['count']['original']} â†’ {sections['count']['modular']}")
    
    # å†…å®¹ç±»å‹åˆ†æ
    print("\nğŸ“ å†…å®¹ç±»å‹åˆ†æ:")
    structure = sections["structure_analysis"]
    for content_type, diff in structure["differences"].items():
        if diff != 0:
            icon = "â¬†ï¸" if diff > 0 else "â¬‡ï¸"
            print(f"   {icon} {content_type}: {structure['original'][content_type]} â†’ {structure['modular'][content_type]} (å·®å¼‚: {diff:+d})")
        else:
            print(f"   âœ… {content_type}: {structure['original'][content_type]} (ä¸€è‡´)")
    
    # å›¾ç‰‡å¯¹æ¯”
    print("\nğŸ–¼ï¸  å›¾ç‰‡å¯¹æ¯”:")
    images = analysis["images_comparison"]
    diff = images["count"]["difference"]
    icon = "â¬†ï¸" if diff > 0 else "â¬‡ï¸" if diff < 0 else "âœ…"
    print(f"   {icon} å›¾ç‰‡æ•°é‡: {images['count']['original']} â†’ {images['count']['modular']} (å·®å¼‚: {diff:+d})")
    
    # å¤„ç†ä¿¡æ¯å¯¹æ¯”
    print("\nâš™ï¸  å¤„ç†ä¿¡æ¯å¯¹æ¯”:")
    processing = analysis["processing_info_comparison"]
    for metric, data in processing.items():
        diff = data["difference"]
        icon = "â¬†ï¸" if diff > 0 else "â¬‡ï¸" if diff < 0 else "âœ…"
        print(f"   {icon} {metric}: {data['original']} â†’ {data['modular']} (å·®å¼‚: {diff:+d})")
    
    # è¯¦ç»†å·®å¼‚
    differences = analysis["detailed_differences"]
    if differences:
        print(f"\nâš ï¸  å‘ç° {len(differences)} å¤„å·®å¼‚ (æ˜¾ç¤ºå‰10ä¸ª):")
        for i, diff in enumerate(differences[:10], 1):
            print(f"   {i:2d}. è·¯å¾„: {diff['path']}")
            print(f"       ç±»å‹: {diff['type']}")
            print(f"       åŸå§‹: {diff['original']}")
            print(f"       æ¨¡å—: {diff['modular']}")
            if 'similarity' in diff:
                print(f"       ç›¸ä¼¼åº¦: {diff['similarity']}")
            print()
    else:
        print("\nâœ… æœªå‘ç°æ˜¾è‘—çš„å†…å®¹å·®å¼‚")
    
    print("="*100)

def main():
    """ä¸»å‡½æ•°"""
    test_file = "Files/PLM2.0/BOM å®¡æ ¸ç”³è¯·.docx"
    
    if not os.path.exists(test_file):
        logger.error(f"æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {test_file}")
        return
    
    logger.info("ğŸ” å¼€å§‹è¯¦ç»†JSONå†…å®¹å¯¹æ¯”æµ‹è¯•")
    logger.info(f"ğŸ“„ æµ‹è¯•æ–‡ä»¶: {test_file}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    original_dir = "json_comparison/original_result"
    modular_dir = "json_comparison/modular_result"
    
    os.makedirs(original_dir, exist_ok=True)
    os.makedirs(modular_dir, exist_ok=True)
    
    # è¿è¡Œä¸¤ä¸ªç‰ˆæœ¬
    logger.info("\n" + "="*60)
    success1 = run_single_test("docx_parser.py", test_file, original_dir)
    
    logger.info("\n" + "="*60)
    success2 = run_single_test("docx_parser_modular.py", test_file, modular_dir)
    
    if not success1 or not success2:
        logger.error("âŒ ä¸€ä¸ªæˆ–å¤šä¸ªæµ‹è¯•å¤±è´¥")
        return
    
    # å¯¹æ¯”JSONå†…å®¹
    original_json = os.path.join(original_dir, "document.json")
    modular_json = os.path.join(modular_dir, "document.json")
    
    if not os.path.exists(original_json) or not os.path.exists(modular_json):
        logger.error("âŒ JSONæ–‡ä»¶ä¸å­˜åœ¨")
        return
    
    analysis = analyze_json_content(original_json, modular_json)
    
    if analysis:
        print_detailed_comparison(analysis)
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        report_file = "json_comparison/detailed_comparison_report.json"
        with open(report_file, "w", encoding="utf-8") as f:
            json.dump(analysis, f, ensure_ascii=False, indent=2)
        
        logger.info(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
    
    logger.info("\nğŸ‰ JSONå†…å®¹å¯¹æ¯”å®Œæˆ!")

if __name__ == "__main__":
    main()
