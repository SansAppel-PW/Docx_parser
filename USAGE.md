# ä½¿ç”¨æŒ‡å—

æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»å¦‚ä½•ä½¿ç”¨DOCXè§£æå™¨çš„å„ç§åŠŸèƒ½ã€‚

## ğŸš€ å¿«é€Ÿå…¥é—¨

### 1. ç¯å¢ƒå‡†å¤‡

ç¡®ä¿æ‚¨çš„Pythonç¯å¢ƒæ»¡è¶³è¦æ±‚ï¼š

```bash
# æ£€æŸ¥Pythonç‰ˆæœ¬ï¼ˆéœ€è¦3.7+ï¼‰
python --version

# å®‰è£…å¿…éœ€ä¾èµ–
pip install python-docx lxml Pillow

# å¯é€‰ï¼šå®‰è£…å¢å¼ºåŠŸèƒ½ä¾èµ–
pip install opencv-python Wand
```

### 2. åŸºæœ¬ä½¿ç”¨

#### æ–¹æ³•ä¸€ï¼šå‘½ä»¤è¡Œä½¿ç”¨

```bash
# å¤„ç†å•ä¸ªæ–‡ä»¶
python docx_parser_modular.py "Files/PLM2.0/BOM å®¡æ ¸ç”³è¯·.docx"

# æ‰¹é‡å¤„ç†æ–‡ä»¶å¤¹
python docx_parser_modular.py Files/PLM2.0

# ä½¿ç”¨é»˜è®¤æ–‡ä»¶å¤¹
python docx_parser_modular.py
```

#### æ–¹æ³•äºŒï¼šPythonä»£ç è°ƒç”¨

```python
from src.parsers.document_parser import parse_docx

# åŸºæœ¬è§£æ
result = parse_docx(
    docx_path="Files/example.docx",
    output_dir="output",
    quick_mode=True  # æ¨èä½¿ç”¨å¿«é€Ÿæ¨¡å¼
)

# æ£€æŸ¥ç»“æœ
if result:
    print(f"âœ… è§£ææˆåŠŸ")
    print(f"ğŸ“„ æ€»èŠ‚ç‚¹æ•°: {len(result.get('sections', []))}")
    print(f"ğŸ–¼ï¸ å›¾ç‰‡æ•°é‡: {len(result.get('images', {}))}")
    print(f"ğŸ¨ SmartArtæ•°é‡: {len(result.get('smartart', {}))}")
    print(f"ğŸ“ åµŒå…¥å¯¹è±¡: {len(result.get('embedded_objects', {}))}")
else:
    print("âŒ è§£æå¤±è´¥")
```

## ğŸ“Š æ‰¹é‡å¤„ç†

### å¤„ç†æ•´ä¸ªæ–‡ä»¶å¤¹

```python
from src.parsers.batch_processor import process_docx_folder

# æ‰¹é‡å¤„ç†
processed_count = process_docx_folder(
    input_folder="Files/PLM2.0",
    output_folder="parsed_results",
    quick_mode=True  # å¯ç”¨å¿«é€Ÿæ¨¡å¼
)

print(f"æˆåŠŸå¤„ç† {processed_count} ä¸ªæ–‡ä»¶")
```

### æŸ¥çœ‹å¤„ç†æŠ¥å‘Š

æ‰¹é‡å¤„ç†å®Œæˆåï¼Œä¼šç”Ÿæˆ `summary.json` æ–‡ä»¶ï¼š

```python
import json

# è¯»å–å¤„ç†æŠ¥å‘Š
with open("parsed_results/summary.json", "r", encoding="utf-8") as f:
    summary = json.load(f)

print(f"æ€»æ–‡ä»¶æ•°: {summary['total_files']}")
print(f"æˆåŠŸå¤„ç†: {summary['processed']}")
print(f"å¤±è´¥æ–‡ä»¶: {summary['failed']}")
print(f"æˆåŠŸç‡: {summary['success_rate']}")
```

## ğŸ¯ é«˜çº§åŠŸèƒ½

### 1. è‡ªå®šä¹‰è¾“å‡ºç›®å½•ç»“æ„

```python
import os
from src.parsers.document_parser import parse_docx

# è‡ªå®šä¹‰è¾“å‡ºç›®å½•
output_base = "custom_output"
doc_name = "æŠ¥å‘Šæ–‡æ¡£"

# åˆ›å»ºè§„èŒƒçš„è¾“å‡ºç›®å½•
output_dir = os.path.join(output_base, doc_name)
os.makedirs(output_dir, exist_ok=True)

# è§£ææ–‡æ¡£
result = parse_docx("document.docx", output_dir, quick_mode=True)
```

### 2. è§£æç»“æœåå¤„ç†

```python
import json

def analyze_document_content(result):
    """åˆ†æè§£æç»“æœ"""
    
    # ç»Ÿè®¡æ–‡æœ¬å†…å®¹
    text_sections = [s for s in result.get('sections', []) 
                    if s.get('type') == 'paragraph' and s.get('text')]
    
    # ç»Ÿè®¡è¡¨æ ¼
    tables = [s for s in result.get('sections', []) 
             if s.get('type') == 'table']
    
    # ç»Ÿè®¡å›¾ç‰‡
    images = result.get('images', {})
    
    # ç»Ÿè®¡SmartArt
    smartarts = result.get('smartart', {})
    
    # ç”Ÿæˆåˆ†ææŠ¥å‘Š
    analysis = {
        "content_summary": {
            "text_paragraphs": len(text_sections),
            "tables": len(tables),
            "images": len(images),
            "smartart_charts": len(smartarts)
        },
        "text_preview": [s.get('text', '')[:100] for s in text_sections[:5]],
        "table_info": [{"rows": len(t.get('data', [])), 
                       "cols": len(t.get('data', [{}])[0]) if t.get('data') else 0} 
                      for t in tables],
        "image_formats": list(set(img.get('format', 'unknown') 
                                 for img in images.values()))
    }
    
    return analysis

# ä½¿ç”¨ç¤ºä¾‹
result = parse_docx("document.docx", "output")
if result:
    analysis = analyze_document_content(result)
    
    # ä¿å­˜åˆ†æç»“æœ
    with open("output/analysis.json", "w", encoding="utf-8") as f:
        json.dump(analysis, f, ensure_ascii=False, indent=2)
```

### 3. é”™è¯¯å¤„ç†å’Œè°ƒè¯•

```python
import logging

# è®¾ç½®è¯¦ç»†æ—¥å¿—
logging.basicConfig(level=logging.DEBUG)

def safe_parse_docx(docx_path, output_dir):
    """å®‰å…¨çš„æ–‡æ¡£è§£æå‡½æ•°"""
    try:
        result = parse_docx(docx_path, output_dir, quick_mode=True)
        
        if not result:
            print(f"âŒ è§£æå¤±è´¥: {docx_path}")
            return None
            
        # æ£€æŸ¥è­¦å‘Šå’Œé”™è¯¯
        processing_info = result.get('processing_info', {})
        warnings = processing_info.get('warnings', [])
        errors = processing_info.get('errors', [])
        
        if warnings:
            print(f"âš ï¸ å‘ç° {len(warnings)} ä¸ªè­¦å‘Š")
            for warning in warnings[:3]:  # æ˜¾ç¤ºå‰3ä¸ªè­¦å‘Š
                print(f"   - {warning}")
                
        if errors:
            print(f"âŒ å‘ç° {len(errors)} ä¸ªé”™è¯¯")
            for error in errors[:3]:  # æ˜¾ç¤ºå‰3ä¸ªé”™è¯¯
                print(f"   - {error}")
        
        return result
        
    except Exception as e:
        print(f"âŒ è§£æå¼‚å¸¸: {docx_path}")
        print(f"   é”™è¯¯è¯¦æƒ…: {str(e)}")
        return None

# ä½¿ç”¨ç¤ºä¾‹
result = safe_parse_docx("Files/example.docx", "output")
```

## ğŸ”§ æ€§èƒ½ä¼˜åŒ–

### 1. å¿«é€Ÿæ¨¡å¼ vs å®Œæ•´æ¨¡å¼

```python
import time

def compare_modes(docx_path):
    """å¯¹æ¯”ä¸åŒæ¨¡å¼çš„æ€§èƒ½"""
    
    # å¿«é€Ÿæ¨¡å¼
    start_time = time.time()
    quick_result = parse_docx(docx_path, "output_quick", quick_mode=True)
    quick_time = time.time() - start_time
    
    # å®Œæ•´æ¨¡å¼
    start_time = time.time()
    full_result = parse_docx(docx_path, "output_full", quick_mode=False)
    full_time = time.time() - start_time
    
    print(f"å¿«é€Ÿæ¨¡å¼: {quick_time:.2f}ç§’")
    print(f"å®Œæ•´æ¨¡å¼: {full_time:.2f}ç§’")
    print(f"æ€§èƒ½æå‡: {(full_time/quick_time):.1f}x")

# ä½¿ç”¨ç¤ºä¾‹
compare_modes("Files/large_document.docx")
```

### 2. å†…å­˜ç®¡ç†

```python
import gc
import psutil
import os

def monitor_memory_usage(func, *args, **kwargs):
    """ç›‘æ§å†…å­˜ä½¿ç”¨æƒ…å†µ"""
    process = psutil.Process(os.getpid())
    
    # è§£æå‰å†…å­˜
    memory_before = process.memory_info().rss / 1024 / 1024  # MB
    
    # æ‰§è¡Œè§£æ
    result = func(*args, **kwargs)
    
    # è§£æåå†…å­˜
    memory_after = process.memory_info().rss / 1024 / 1024  # MB
    
    # æ‰‹åŠ¨åƒåœ¾å›æ”¶
    gc.collect()
    memory_final = process.memory_info().rss / 1024 / 1024  # MB
    
    print(f"è§£æå‰å†…å­˜: {memory_before:.1f}MB")
    print(f"è§£æåå†…å­˜: {memory_after:.1f}MB")
    print(f"å›æ”¶åå†…å­˜: {memory_final:.1f}MB")
    print(f"å†…å­˜å¢é•¿: {memory_after - memory_before:.1f}MB")
    
    return result

# ä½¿ç”¨ç¤ºä¾‹
result = monitor_memory_usage(
    parse_docx, 
    "Files/large_document.docx", 
    "output", 
    quick_mode=True
)
```

## ğŸ“ è¾“å‡ºç»“æœè¯´æ˜

### ç›®å½•ç»“æ„

```
output_dir/
â”œâ”€â”€ document.json       # ä¸»è¦è§£æç»“æœ
â”œâ”€â”€ images/            # æå–çš„å›¾ç‰‡æ–‡ä»¶
â”‚   â”œâ”€â”€ img_001.png
â”‚   â”œâ”€â”€ img_002.jpg
â”‚   â””â”€â”€ ...
â”œâ”€â”€ smartart/          # SmartArtå›¾è¡¨JSONæ–‡ä»¶
â”‚   â”œâ”€â”€ smartart_001.json
â”‚   â””â”€â”€ ...
â”œâ”€â”€ embedded_objects/  # åµŒå…¥å¯¹è±¡
â”‚   â”œâ”€â”€ embedded_obj_001.json
â”‚   â””â”€â”€ ...
â””â”€â”€ files/            # å…¶ä»–æ–‡ä»¶
```

### JSONç»“æ„è¯¦è§£

```json
{
  "metadata": {
    "title": "æ–‡æ¡£æ ‡é¢˜",
    "author": "æ–‡æ¡£ä½œè€…", 
    "subject": "æ–‡æ¡£ä¸»é¢˜",
    "created": "2024-01-01T10:00:00",
    "modified": "2024-01-02T15:30:00",
    "pages": 10,
    "words": 5000,
    "paragraphs": 100
  },
  "sections": [
    {
      "type": "paragraph",
      "text": "æ®µè½æ–‡æœ¬å†…å®¹",
      "level": 1,
      "style": "æ ‡é¢˜1",
      "alignment": "left",
      "content": []  // å­å†…å®¹ï¼ˆå›¾ç‰‡ã€è¡¨æ ¼ç­‰ï¼‰
    },
    {
      "type": "table", 
      "rows": 3,
      "columns": 4,
      "data": [
        ["å•å…ƒæ ¼1", "å•å…ƒæ ¼2", "å•å…ƒæ ¼3", "å•å…ƒæ ¼4"],
        ["æ•°æ®1", "æ•°æ®2", "æ•°æ®3", "æ•°æ®4"]
      ]
    }
  ],
  "images": {
    "img_12345678": {
      "url": "images/img_12345678.png",
      "format": "png",
      "width": 800,
      "height": 600,
      "size": "150.23 KB",
      "context": "æ®µè½ä¸­çš„å›¾ç‰‡"
    }
  },
  "smartart": {
    "smartart_12345678": {
      "title": "ç»„ç»‡æ¶æ„å›¾",
      "type": "hierarchy",
      "layout": "org_chart",
      "nodes": [
        {
          "text": "CEO",
          "level": 0,
          "children": ["node_001", "node_002"]
        }
      ]
    }
  },
  "embedded_objects": {
    "embedded_obj_12345678": {
      "type": "visio",
      "title": "æµç¨‹å›¾",
      "size": "2.5 MB",
      "preview_image": "images/embedded_preview_12345678.png"
    }
  },
  "processing_info": {
    "total_time": "2.34 seconds",
    "quick_mode": true,
    "warnings": [],
    "errors": []
  }
}
```

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é”™è¯¯è§£å†³æ–¹æ¡ˆ

1. **ImportError: No module named 'docx'**
   ```bash
   pip install python-docx
   ```

2. **Wandç›¸å…³é”™è¯¯**
   ```bash
   # macOS
   brew install imagemagick
   pip install Wand
   
   # Ubuntu
   sudo apt-get install imagemagick libmagickwand-dev
   pip install Wand
   ```

3. **å†…å­˜ä¸è¶³é”™è¯¯**
   - ä½¿ç”¨å¿«é€Ÿæ¨¡å¼: `quick_mode=True`
   - åˆ†æ‰¹å¤„ç†å¤§æ–‡ä»¶
   - å¢åŠ ç³»ç»Ÿå†…å­˜

4. **æ–‡ä»¶æƒé™é”™è¯¯**
   ```bash
   # ç¡®ä¿æœ‰è¯»å†™æƒé™
   chmod 755 Files/
   chmod 644 Files/*.docx
   ```

### è°ƒè¯•æŠ€å·§

1. **å¯ç”¨è¯¦ç»†æ—¥å¿—**
   ```python
   import logging
   logging.basicConfig(level=logging.DEBUG)
   ```

2. **æ£€æŸ¥æ–‡ä»¶å®Œæ•´æ€§**
   ```python
   from zipfile import ZipFile
   
   def check_docx_file(docx_path):
       try:
           with ZipFile(docx_path, 'r') as zip_file:
               # æ£€æŸ¥å¿…è¦æ–‡ä»¶
               required_files = ['word/document.xml', '[Content_Types].xml']
               for file in required_files:
                   if file not in zip_file.namelist():
                       print(f"âŒ ç¼ºå°‘å¿…è¦æ–‡ä»¶: {file}")
                       return False
               print("âœ… DOCXæ–‡ä»¶ç»“æ„æ­£å¸¸")
               return True
       except Exception as e:
           print(f"âŒ æ–‡ä»¶æŸå: {e}")
           return False
   ```

3. **æ€§èƒ½åˆ†æ**
   ```python
   import cProfile
   
   def profile_parsing(docx_path):
       """æ€§èƒ½åˆ†æ"""
       cProfile.run(
           f'parse_docx("{docx_path}", "output", quick_mode=True)',
           'profile_stats.txt'
       )
   ```

## ğŸ“š APIå‚è€ƒ

### ä¸»è¦å‡½æ•°

#### `parse_docx(docx_path, output_dir, quick_mode=True)`

è§£æå•ä¸ªDOCXæ–‡æ¡£ã€‚

**å‚æ•°:**
- `docx_path` (str): DOCXæ–‡ä»¶è·¯å¾„
- `output_dir` (str): è¾“å‡ºç›®å½•è·¯å¾„  
- `quick_mode` (bool): æ˜¯å¦å¯ç”¨å¿«é€Ÿæ¨¡å¼ï¼Œé»˜è®¤True

**è¿”å›:**
- `dict` | `None`: è§£æç»“æœå­—å…¸ï¼Œå¤±è´¥æ—¶è¿”å›None

#### `process_docx_folder(input_folder, output_folder, quick_mode=True)`

æ‰¹é‡å¤„ç†æ–‡ä»¶å¤¹ä¸­çš„DOCXæ–‡æ¡£ã€‚

**å‚æ•°:**
- `input_folder` (str): è¾“å…¥æ–‡ä»¶å¤¹è·¯å¾„
- `output_folder` (str): è¾“å‡ºæ–‡ä»¶å¤¹è·¯å¾„
- `quick_mode` (bool): æ˜¯å¦å¯ç”¨å¿«é€Ÿæ¨¡å¼ï¼Œé»˜è®¤True

**è¿”å›:**
- `int`: æˆåŠŸå¤„ç†çš„æ–‡ä»¶æ•°é‡

---

æ›´å¤šè¯¦ç»†ä¿¡æ¯è¯·å‚è€ƒæºä»£ç æ³¨é‡Šå’Œç¤ºä¾‹æ–‡ä»¶ã€‚
