#!/usr/bin/env python3
"""
DOCXè§£æå™¨ - æ¨¡å—åŒ–ç‰ˆæœ¬
é«˜æ€§èƒ½çš„Wordæ–‡æ¡£è§£æå·¥å…·ï¼Œæ”¯æŒæå–æ–‡æœ¬ã€å›¾ç‰‡ã€SmartArtå’ŒåµŒå…¥å¯¹è±¡

ä½¿ç”¨æ–¹æ³•:
    # å¤„ç†å•ä¸ªæ–‡ä»¶
    python docx_parser_modular.py Files/example.docx
    
    # æ‰¹é‡å¤„ç†æ–‡ä»¶å¤¹
    python docx_parser_modular.py Files/PLM2.0
    
    # å¿«é€Ÿæµ‹è¯•
    python quick_parse_example.py
"""

import sys
import os
import json
import logging

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from src.parsers.document_parser import parse_docx
from src.parsers.batch_processor import process_docx_folder
from src.processors.text_processor import process_document_to_text
from src.utils.text_utils import safe_filename

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("docx_parser.log"),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

def main():
    """ä¸»å‡½æ•°"""
    # ç¤ºä¾‹ä½¿ç”¨ - å¯ä»¥å¤„ç†å•ä¸ªæ–‡ä»¶æˆ–æ‰¹é‡å¤„ç†æ–‡ä»¶å¤¹
    if len(sys.argv) > 1:
        input_path = sys.argv[1]
    else:
        input_path = "Files/PLM2.0"  # é»˜è®¤DOCXæ–‡ä»¶å¤¹è·¯å¾„
    
    # æ£€æŸ¥è¾“å…¥è·¯å¾„æ˜¯å¦å­˜åœ¨
    if not os.path.exists(input_path):
        logger.error(f"è¾“å…¥è·¯å¾„ä¸å­˜åœ¨: {input_path}")
        sys.exit(1)
    
    # åˆ¤æ–­æ˜¯å•ä¸ªæ–‡ä»¶è¿˜æ˜¯æ–‡ä»¶å¤¹
    if os.path.isfile(input_path):
        # å¤„ç†å•ä¸ªæ–‡ä»¶
        if not input_path.lower().endswith('.docx'):
            logger.error(f"ä¸æ˜¯æœ‰æ•ˆçš„DOCXæ–‡ä»¶: {input_path}")
            sys.exit(1)
        
        # ä¸ºå•ä¸ªæ–‡ä»¶åˆ›å»ºè¾“å‡ºç›®å½•
        file_basename = os.path.splitext(os.path.basename(input_path))[0]
        safe_name = safe_filename(file_basename)
        output_dir = f"parsed_docs/single_files/{safe_name}"
        os.makedirs(output_dir, exist_ok=True)
        
        logger.info(f"å¼€å§‹å¤„ç†å•ä¸ªæ–‡ä»¶: {input_path}")
        logger.info(f"è¾“å‡ºç›®å½•: {output_dir}")
        
        # è§£ææ–‡æ¡£ï¼ˆä½¿ç”¨å¿«é€Ÿæ¨¡å¼ï¼‰
        document_structure = parse_docx(input_path, output_dir, quick_mode=True)
        
        if document_structure:
            # ä¿å­˜ä¸ºJSONæ–‡ä»¶
            json_path = os.path.join(output_dir, "document.json")
            with open(json_path, "w", encoding="utf-8") as f:
                json.dump(document_structure, f, ensure_ascii=False, indent=2)
            
            # å¤„ç†ä¸ºæ ‡å‡†åŒ–æ–‡æœ¬æ ¼å¼
            try:
                # ä»æ–‡ä»¶åæå–æ–‡æ¡£åç§°
                doc_name = safe_name
                processed_text = process_document_to_text(document_structure, doc_name)
                
                # ä¿å­˜å¤„ç†åçš„æ–‡æœ¬
                text_path = os.path.join(output_dir, "processed_text.txt")
                with open(text_path, "w", encoding="utf-8") as f:
                    f.write(processed_text)
                
                logger.info(f"æ ‡å‡†åŒ–æ–‡æœ¬å·²ä¿å­˜åˆ°: {text_path}")
                
            except Exception as e:
                logger.error(f"æ–‡æœ¬å¤„ç†å¤±è´¥: {e}")
            
            # ç»Ÿè®¡ä¿¡æ¯
            total_images = len(document_structure.get("images", {}))
            processing_info = document_structure.get("processing_info", {})
            warnings = len(processing_info.get("warnings", []))
            errors = len(processing_info.get("errors", []))
            
            logger.info(f"æ–‡ä»¶å¤„ç†å®Œæˆ!")
            logger.info(f"è¾“å‡ºä½ç½®: {output_dir}")
            logger.info(f"å›¾ç‰‡æ•°é‡: {total_images}")
            logger.info(f"è­¦å‘Šæ•°é‡: {warnings}")
            logger.info(f"é”™è¯¯æ•°é‡: {errors}")
            
            if warnings > 0 or errors > 0:
                logger.info("è¯¦ç»†çš„è­¦å‘Šå’Œé”™è¯¯ä¿¡æ¯è¯·æŸ¥çœ‹ document.json æ–‡ä»¶")
        else:
            logger.error("æ–‡ä»¶å¤„ç†å¤±è´¥")
            sys.exit(1)
            
    elif os.path.isdir(input_path):
        # æ‰¹é‡å¤„ç†æ–‡ä»¶å¤¹
        # åˆ›å»ºä¸è¾“å…¥æ–‡ä»¶å¤¹å¯¹åº”çš„è¾“å‡ºç›®å½•
        folder_name = os.path.basename(input_path.rstrip('/'))
        output_base_dir = f"parsed_docs/{folder_name}_parsed"  # è¾“å‡ºç›®å½•
        
        logger.info(f"å¼€å§‹æ‰¹é‡å¤„ç†æ–‡ä»¶å¤¹: {input_path}")
        logger.info(f"è¾“å‡ºç›®å½•: {output_base_dir}")
        
        # å¤„ç†æ‰€æœ‰DOCXæ–‡ä»¶
        processed_count = process_docx_folder(input_path, output_base_dir, quick_mode=True)
        
        # æ‰“å°æ€»ç»“æŠ¥å‘Š
        if processed_count and processed_count > 0:
            summary_path = os.path.join(output_base_dir, "summary.json")
            if os.path.exists(summary_path):
                with open(summary_path, "r", encoding="utf-8") as f:
                    summary = json.load(f)
                    print("\n" + "="*60)
                    print("ğŸ“Š å¤„ç†æ€»ç»“æŠ¥å‘Š")
                    print("="*60)
                    print(f"ğŸ“ å¤„ç†æ–‡ä»¶å¤¹: {summary['input_folder']}")
                    print(f"ğŸ“„ æ–‡ä»¶æ€»æ•°: {summary['total_files']}")
                    print(f"âœ… æˆåŠŸå¤„ç†: {summary['processed']}")
                    print(f"âŒ å¤±è´¥æ–‡ä»¶: {summary['failed']}")
                    print(f"ğŸ“ˆ æˆåŠŸç‡: {summary.get('success_rate', 'N/A')}")
                    
                    if summary.get('failed_files'):
                        print("\nâŒ å¤±è´¥æ–‡ä»¶åˆ—è¡¨:")
                        for failed in summary['failed_files'][:20]:
                            print(f"   - {failed.get('file', 'Unknown')}: {failed.get('error', 'Unknown error')}")
                        if len(summary['failed_files']) > 20:
                            print(f"   ... è¿˜æœ‰ {len(summary['failed_files'])-20} ä¸ªå¤±è´¥æ–‡ä»¶")

                    print(f"\nğŸ“ ç»“æœä¿å­˜åœ¨: {output_base_dir}")
                    print("="*60)
        else:
            logger.error("æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•æ–‡ä»¶")
            sys.exit(1)
    else:
        logger.error(f"æ— æ³•è¯†åˆ«çš„è¾“å…¥è·¯å¾„ç±»å‹: {input_path}")
        sys.exit(1)

if __name__ == "__main__":
    main()
